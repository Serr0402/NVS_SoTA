{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1OxYSSGuUXVwK7lWr1iATDTn9fRAkoiVl","authorship_tag":"ABX9TyOnVxHyyAJvAloAFqEfCPZl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b20e5e1ce6494f0da7eb0894446a4480":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c875d1927f3c4c7d846e05ea154b6751","IPY_MODEL_2ae72372d42c438aac943e9d2114daaa","IPY_MODEL_b213b4a9416e48a7a0d65f3149b0dd5e"],"layout":"IPY_MODEL_dd88173e55cf487e9124529494ee5b73"}},"c875d1927f3c4c7d846e05ea154b6751":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a95cee9f5a9b4935a879cb99ebc8b9f4","placeholder":"​","style":"IPY_MODEL_6d84c0192ab24f4e995b9777ee0981e4","value":"open_clip_model.safetensors: 100%"}},"2ae72372d42c438aac943e9d2114daaa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92f8b5e2d36b48f99844be00aadd1482","max":3944517836,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e827753424e0405ab2db25357ee2f06d","value":3944517836}},"b213b4a9416e48a7a0d65f3149b0dd5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae48b56512e442f48c1072d3872610eb","placeholder":"​","style":"IPY_MODEL_10753e5cc3ee4a08aaa3f114206c4426","value":" 3.94G/3.94G [07:22&lt;00:00, 6.66MB/s]"}},"dd88173e55cf487e9124529494ee5b73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a95cee9f5a9b4935a879cb99ebc8b9f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d84c0192ab24f4e995b9777ee0981e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92f8b5e2d36b48f99844be00aadd1482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e827753424e0405ab2db25357ee2f06d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae48b56512e442f48c1072d3872610eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10753e5cc3ee4a08aaa3f114206c4426":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion"],"metadata":{"id":"KYrwIDBra5aU"}},{"cell_type":"markdown","source":["The model can be found on [GitHub](https://github.com/Stability-AI/generative-models). The checkpoint is located on their [HugginFace](https://huggingface.co/stabilityai/sv3d/tree/main).\n","\n","The script *simple_video_sample.py* has been adapted to be used in this Jupyter notebook"],"metadata":{"id":"WuGJX1OOeBvL"}},{"cell_type":"markdown","source":["##Installation and setup"],"metadata":{"id":"v8KdXP-NbvnF"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"db79-F3ea4IS","executionInfo":{"status":"ok","timestamp":1743843740199,"user_tz":-120,"elapsed":244820,"user":{"displayName":"Celia Redondo Verdú","userId":"09853717486431194470"}},"outputId":"447831f2-75fd-468d-ef7c-4cc38c4ac93e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu118\n","Collecting torchvision==0.16.0\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n","Collecting torch==2.1.0 (from torchvision==0.16.0)\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m574.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchvision==0.16.0) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchvision==0.16.0) (4.13.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchvision==0.16.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchvision==0.16.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchvision==0.16.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchvision==0.16.0) (2025.3.2)\n","Collecting triton==2.1.0 (from torch==2.1.0->torchvision==0.16.0)\n","  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0->torchvision==0.16.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0->torchvision==0.16.0) (1.3.0)\n","Installing collected packages: triton, torch, torchvision\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.1.0+cu118 torchvision-0.16.0+cu118 triton-2.1.0\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement matplotli (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for matplotli\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n","Collecting rembg\n","  Downloading rembg-2.0.65-py3-none-any.whl.metadata (20 kB)\n","Collecting fire\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting omegaconf\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from rembg) (4.23.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from rembg) (4.11.0.86)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from rembg) (11.1.0)\n","Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from rembg) (1.8.2)\n","Collecting pymatting (from rembg)\n","  Downloading PyMatting-1.1.13-py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from rembg) (0.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from rembg) (1.14.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire) (3.0.1)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.24.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (4.3.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.11/dist-packages (from pymatting->rembg) (0.60.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (3.4.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2025.3.30)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (0.4)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.43.0)\n","Downloading rembg-2.0.65-py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyMatting-1.1.13-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: fire, antlr4-python3-runtime\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=c1c235d17ea38e16f19058202cbc6d6797e2ba9e3aef71d6a25a89c75c3ba63c\n","  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=8c5e0a239fe8d419f8b7e3ac06addeb72f171efd0630d3f5447f448f3ac1a783\n","  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n","Successfully built fire antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf, fire, pymatting, rembg\n","Successfully installed antlr4-python3-runtime-4.9.3 fire-0.7.0 omegaconf-2.3.0 pymatting-1.1.13 rembg-2.0.65\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]},"id":"667acc0f0d694623a7a58859cbfdf536"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n","Collecting onnxruntime-gpu\n","  Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n","Collecting coloredlogs (from onnxruntime-gpu)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (24.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (5.29.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.13.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n","Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.21.0\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-pmhvkl10\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-pmhvkl10\n","  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy (from clip==1.0)\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.16.0+cu118)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.13.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.32.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (2025.1.31)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n","Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=0106559eded263e28210a79f63004b05c69b402cdd4a0fbe8988fee3f29b5f49\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-erzggf01/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n","Successfully built clip\n","Installing collected packages: ftfy, clip\n","Successfully installed clip-1.0 ftfy-6.3.1\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.2)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n","  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (24.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.13.0)\n","Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.18.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.1.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.3.1)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.1.0->pytorch_lightning) (1.3.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n","Downloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n","Successfully installed lightning-utilities-0.14.3 pytorch_lightning-2.5.1 torchmetrics-1.7.0\n","Collecting kornia\n","  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n","Collecting kornia_rs>=0.1.0 (from kornia)\n","  Downloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia) (24.2)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from kornia) (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (4.13.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (2025.3.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n","Downloading kornia-0.8.0-py2.py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kornia_rs, kornia\n","Successfully installed kornia-0.8.0 kornia_rs-0.1.8\n","Collecting open-clip-torch\n","  Downloading open_clip_torch-2.31.0-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.16.0+cu118)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2024.11.6)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (6.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (4.67.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.30.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.5.3)\n","Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (1.0.15)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (4.13.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (2025.3.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (2.1.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open-clip-torch) (0.2.13)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (2.32.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open-clip-torch) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open-clip-torch) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->open-clip-torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2025.1.31)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\n","Downloading open_clip_torch-2.31.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: open-clip-torch\n","Successfully installed open-clip-torch-2.31.0\n","\u001b[33mWARNING: Skipping imwatermark as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping imhist as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mCollecting git+https://github.com/guofei9987/imwatermark.git\n","  Cloning https://github.com/guofei9987/imwatermark.git to /tmp/pip-req-build-tio5z4tk\n","  Running command git clone --filter=blob:none --quiet https://github.com/guofei9987/imwatermark.git /tmp/pip-req-build-tio5z4tk\n","  fatal: could not read Username for 'https://github.com': No such device or address\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/guofei9987/imwatermark.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-tio5z4tk\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/guofei9987/imwatermark.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-tio5z4tk\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"]}],"source":["# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install --upgrade torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118\n","\n","!pip install transformers einops opencv-python matplotli\n","!pip install transformers einops rembg fire omegaconf safetensors imageio\n","!pip install opencv-python-headless  # to avoid GUI-related errors in Colab\n","!pip install onnxruntime-gpu\n","!pip install git+https://github.com/openai/CLIP.git\n","!pip install pytorch_lightning\n","!pip install kornia\n","!pip install open-clip-torch\n","\n","!pip uninstall -y imwatermark imhist\n","!pip install git+https://github.com/guofei9987/imwatermark.git\n"]},{"cell_type":"code","source":["# Clone the StabilityAI repo\n","!git clone https://github.com/Stability-AI/generative-models\n","%cd generative-models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ax3CWH0LdH5e","executionInfo":{"status":"ok","timestamp":1743843747208,"user_tz":-120,"elapsed":7007,"user":{"displayName":"Celia Redondo Verdú","userId":"09853717486431194470"}},"outputId":"6f6b16c0-424e-4b28-c836-087e37bec478"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'generative-models'...\n","remote: Enumerating objects: 1119, done.\u001b[K\n","remote: Counting objects: 100% (554/554), done.\u001b[K\n","remote: Compressing objects: 100% (169/169), done.\u001b[K\n","remote: Total 1119 (delta 428), reused 412 (delta 384), pack-reused 565 (from 1)\u001b[K\n","Receiving objects: 100% (1119/1119), 86.66 MiB | 15.54 MiB/s, done.\n","Resolving deltas: 100% (589/589), done.\n","/content/generative-models\n"]}]},{"cell_type":"markdown","source":["##Load the check point"],"metadata":{"id":"YEjlFOQKdN_S"}},{"cell_type":"code","source":["import requests\n","\n","# Create checkpoint directory\n","import os\n","os.makedirs(\"checkpoints\", exist_ok=True)\n"],"metadata":{"id":"Btbb3BTAdQrr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qCywvFuXFWMn","executionInfo":{"status":"ok","timestamp":1743843867702,"user_tz":-120,"elapsed":120020,"user":{"displayName":"Celia Redondo Verdú","userId":"09853717486431194470"}},"outputId":"49df031d-6ddf-4486-822c-1b148055367f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["checkpoint_path = \"/content/drive/MyDrive/0-Master/TAVA_NVS/sv3d_u.safetensors\"\n","\n","import os\n","\n","if os.path.exists(checkpoint_path):\n","    print(\"Found checkpoint!\")\n","else:\n","    print(\"Checkpoint not found. Double-check the path.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4LyLG9bFaIK","executionInfo":{"status":"ok","timestamp":1743843867800,"user_tz":-120,"elapsed":99,"user":{"displayName":"Celia Redondo Verdú","userId":"09853717486431194470"}},"outputId":"ed4627ac-a681-48b9-a1f4-263f09a7b400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found checkpoint!\n"]}]},{"cell_type":"code","source":["target_path = \"/content/generative-models/checkpoints/sv3d_u.safetensors\"\n","\n","# Create checkpoints folder if it doesn't exist\n","os.makedirs(os.path.dirname(target_path), exist_ok=True)\n","\n","# Copy from Drive to repo\n","import shutil\n","shutil.copy(checkpoint_path, target_path)\n","\n","print(\"Copied to:\", target_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0X-2GyGFh6q","executionInfo":{"status":"ok","timestamp":1743844038713,"user_tz":-120,"elapsed":170913,"user":{"displayName":"Celia Redondo Verdú","userId":"09853717486431194470"}},"outputId":"8ec7de9a-3e9a-4489-fae4-92d7e38d86b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied to: /content/generative-models/checkpoints/sv3d_u.safetensors\n"]}]},{"cell_type":"markdown","source":["##Load Input"],"metadata":{"id":"hWz_ja4mfaic"}},{"cell_type":"markdown","source":["##Run the model"],"metadata":{"id":"jxgf1vmKfqjZ"}},{"cell_type":"code","source":["!sed -i '/from imwatermark import WatermarkEncoder/d' sgm/inference/helpers.py\n","!sed -i 's/samples = embed_watermark(samples)/# samples = embed_watermark(samples)/' scripts/sampling/simple_video_sample.py\n","!sed -i '/self.encoder = WatermarkEncoder()/d' sgm/inference/helpers.py\n","!sed -i '/self.encoder.set_watermark(\"bits\", self.watermark)/d' sgm/inference/helpers.py\n","!sed -i 's/    def __init__(self, watermark):/    def __init__(self, watermark):\\n        pass/' sgm/inference/helpers.py\n","!sed -i 's/    def __call__(self, images):/    def __call__(self, images):\\n        return images/' sgm/inference/helpers.py\n"],"metadata":{"id":"kz4Lw581nMJL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('.')  # ensure base dir is in path\n","\n","# Create a wrapper to run from notebook\n","from scripts.sampling.simple_video_sample import sample\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"17eDV3i7fsof","executionInfo":{"status":"ok","timestamp":1743844130979,"user_tz":-120,"elapsed":91696,"user":{"displayName":"Celia Redondo Verdú","userId":"09853717486431194470"}},"outputId":"70805f2b-9cd6-4b74-9835-438f073dd378"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","A module that was compiled using NumPy 1.x cannot be run in\n","NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n","versions of NumPy, modules must be compiled with NumPy 2.0.\n","Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n","\n","If you are a user of the module, the easiest solution will be to\n","downgrade to 'numpy<2' or try to upgrade the affected module.\n","We expect that some modules will need time to support NumPy 2.\n","\n","Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n","    await self.process_one()\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n","    await dispatch(*args)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n","    await result\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n","    reply_content = await reply_content\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n","    res = shell.run_cell(\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n","    return super().run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-8-44fe4cf9c71c>\", line 5, in <cell line: 0>\n","    from scripts.sampling.simple_video_sample import sample\n","  File \"/content/generative-models/scripts/sampling/simple_video_sample.py\", line 12, in <module>\n","    import torch\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n","    from .functional import *  # noqa: F403\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n","    import torch.nn.functional as F\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n","    from .modules import *  # noqa: F403\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n","    from .transformer import TransformerEncoder, TransformerDecoder, \\\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n","    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n","  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n","WARNING:sgm.modules.diffusionmodules.model:no module 'xformers'. Processing without...\n","WARNING:sgm.modules.attention:no module 'xformers'. Processing without...\n"]}]},{"cell_type":"code","source":["import torch\n","torch.cuda.empty_cache()\n"],"metadata":{"id":"gHrcozwcKqeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_path = \"/content/drive/MyDrive/0-Master/TAVA_NVS/0.jpg\"\n","\n","sample(\n","    input_path=input_path,\n","    version=\"sv3d_u\",\n","    device=\"cpu\",\n","    decoding_t=1,              # 1 frame at a time (least memory)\n","    motion_bucket_id=64,      # lower motion = less compute\n","    fps_id=6,                  # moderate frame rate\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":849,"referenced_widgets":["b20e5e1ce6494f0da7eb0894446a4480","c875d1927f3c4c7d846e05ea154b6751","2ae72372d42c438aac943e9d2114daaa","b213b4a9416e48a7a0d65f3149b0dd5e","dd88173e55cf487e9124529494ee5b73","a95cee9f5a9b4935a879cb99ebc8b9f4","6d84c0192ab24f4e995b9777ee0981e4","92f8b5e2d36b48f99844be00aadd1482","e827753424e0405ab2db25357ee2f06d","ae48b56512e442f48c1072d3872610eb","10753e5cc3ee4a08aaa3f114206c4426"]},"id":"9tuqtgv1ifeI","outputId":"cc101a5f-f655-4df3-c57d-25fdc22bb6a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n","WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n","VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n","WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n","VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n","WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.1.0+cu118.\n"]},{"output_type":"stream","name":"stdout","text":["VideoTransformerBlock is using checkpointing\n","VideoTransformerBlock is using checkpointing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["open_clip_model.safetensors:   0%|          | 0.00/3.94G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b20e5e1ce6494f0da7eb0894446a4480"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Initialized embedder #0: FrozenOpenCLIPImagePredictionEmbedder with 683800065 params. Trainable: False\n","Initialized embedder #1: VideoPredictionEmbedderWithEncoder with 83653863 params. Trainable: False\n","Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n","Restored from checkpoints/sv3d_u.safetensors with 0 missing and 0 unexpected keys\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 890M/890M [00:58<00:00, 16.0MiB/s]\n"]}]}]}